{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classifiers import seqDenseNN, seqDenseLSTM, seqCNN\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "def splitData(xTrain, yTrain, labeledSize, selectionType):\n",
    "    idx = np.array([])\n",
    "    if (selectionType == \"Group\"):\n",
    "        labels = np.unique(yTrain)\n",
    "        size = int(labeledSize/len(labels))\n",
    "        for label in labels:\n",
    "            idx = np.append(idx, np.random.choice(np.where(yTrain == label)[0], \n",
    "                                                  size, replace = False))\n",
    "            np.random.shuffle(idx)\n",
    "    else:\n",
    "        idx = np.random.choice(yTrain.shape[0], labeledSize, replace = False)\n",
    "    idx = idx.astype(int)\n",
    "    labeledXTrain = xTrain[idx, ]\n",
    "    labeledYTrain = yTrain[idx, ]\n",
    "    \n",
    "    unlabeledXTrain = xTrain[[i for i in range(xTrain.shape[0]) if i not in idx], ]\n",
    "    unlabeledYTrain = yTrain[[i for i in range(xTrain.shape[0]) if i not in idx], ]\n",
    "    return([labeledXTrain, labeledYTrain, unlabeledXTrain, unlabeledYTrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfTrainImageModel(xTrain, yTrain, batchSize, maxIter, pThresh, labeledSize, selectionType, \n",
    "                        induceError, errorDenom, layerSize, dropout, regLambda, model):\n",
    "    # Assumes that the classification model can also calculate class probabilities\n",
    "    \n",
    "    # 1. Randomly classify data as labeled and unlabeled according to label size\n",
    "    data = splitData(xTrain, yTrain, labeledSize, selectionType)\n",
    "    labeledXTrain = data[0]\n",
    "    labeledYTrain = data[1]    \n",
    "    unlabeledXTrain = data[2]\n",
    "    unlabeledYTrain = data[3]\n",
    "    \n",
    "    unlabeledData = np.copy(unlabeledYTrain)\n",
    "    seqDenseModel = seqDenseNN(labeledXTrain, layerSize, dropout, regLambda)\n",
    "    if model == 'CNN':\n",
    "        seqDenseModel = seqCNN(xTrain, layerSize, dropout)\n",
    "    labeledYTrain = to_categorical(labeledYTrain, 10)\n",
    "    unlabeledYTrain = to_categorical(unlabeledYTrain, 10)\n",
    "    \n",
    "    count = 0\n",
    "    wrongLabePct = []\n",
    "    shouldRandomizeFirstPrediction = induceError\n",
    "    # Check if there are any more unlabeled datapoints left or if the number of iterations are done\n",
    "    while((count <= maxIter) and (len(unlabeledData) != 0)):\n",
    "        print(count)\n",
    "        print(len(unlabeledData))\n",
    "        # 2. Run a CNN on labeled data and get predicted labels and probabilities\n",
    "        seqDenseModel.fit(labeledXTrain, labeledYTrain, batch_size = batchSize, epochs = 5,  \n",
    "                     validation_split = 0.1, verbose = 0)\n",
    "        unlabeledYHat = seqDenseModel.predict_classes(unlabeledXTrain, batch_size = batchSize)\n",
    "        predProbs = seqDenseModel.predict(unlabeledXTrain, batch_size = batchSize)\n",
    "        \n",
    "        # 3. Choose datapoints with high label probabilities and add them to labaled set\n",
    "        highProbIdx = np.where(predProbs > pThresh)[0]\n",
    "        labeledXTrain = np.vstack((labeledXTrain, unlabeledXTrain[highProbIdx, :]))\n",
    "        yIdx = highProbIdx\n",
    "        if (shouldRandomizeFirstPrediction):\n",
    "            np.random.shuffle(yIdx[0:int(len(highProbIdx)/errorDenom)])\n",
    "            #shouldRandomizeFirstPrediction = False\n",
    "        labeledYTrain = np.vstack((labeledYTrain, to_categorical(unlabeledYHat[yIdx], 10)))\n",
    "        # Check how much of the unlabeled data that was added to labeled data was wrongly classified\n",
    "        unlabeledYHat = unlabeledYHat[highProbIdx]        \n",
    "        cMat = confusion_matrix(np.argmax(unlabeledYTrain[highProbIdx, :], axis = -1), unlabeledYHat)\n",
    "        print('Prob Idx Size ', highProbIdx.shape)\n",
    "        errorPct = 0\n",
    "        if unlabeledYTrain[highProbIdx, :].shape[0] > 0:\n",
    "            errorPct = 1 - sum(np.diag(cMat))/sum(sum(cMat))\n",
    "        wrongLabePct = np.append(wrongLabePct, errorPct)\n",
    "        \n",
    "        # Remove unlabeled data that was added to labeled data from labeled data\n",
    "        unlabeledXTrain = unlabeledXTrain[[i for i in range(unlabeledXTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledYTrain = unlabeledYTrain[[i for i in range(unlabeledYTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledData = np.copy(unlabeledYTrain)\n",
    "        count += 1\n",
    "    return([seqDenseModel, wrongLabePct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coTrainImageModel(xTrain, yTrain, batchSize, maxIter, pThresh, labeledSize, selectionType, \n",
    "                        induceError, errorDenom, layerSize, dropout, regLambda):\n",
    "    # Assumes that the classification model can also calculate class probabilities\n",
    "    \n",
    "    # 1. Randomly classify data as labeled and unlabeled according to label size\n",
    "    data = splitData(xTrain, yTrain, labeledSize, selectionType)\n",
    "    labeledXTrain = data[0]\n",
    "    labeledYTrain = data[1]    \n",
    "    unlabeledXTrain = data[2]\n",
    "    unlabeledYTrain = data[3]\n",
    "    \n",
    "    unlabeledData = np.copy(unlabeledYTrain)\n",
    "    model1 = seqDenseNN(labeledXTrain, layerSize, dropout, regLambda)\n",
    "    model2 = seqCNN(xTrain, layerSize, dropout)\n",
    "    \n",
    "    labeledYTrain = to_categorical(labeledYTrain, 10)\n",
    "    unlabeledYTrain = to_categorical(unlabeledYTrain, 10)\n",
    "    \n",
    "    count = 0\n",
    "    wrongLabePct = []\n",
    "    shouldRandomizeFirstPrediction = induceError\n",
    "    # Check if there are any more unlabeled datapoints left or if the number of iterations are done\n",
    "    while((count <= maxIter) and (len(unlabeledData) != 0)):\n",
    "        print(count)\n",
    "        print(len(unlabeledData))\n",
    "        # 2. Run a CNN on labeled data and get predicted labels and probabilities\n",
    "        labeledXTrain = labeledXTrain.reshape(labeledXTrain.shape[0], 784)\n",
    "        unlabeledXTrain = unlabeledXTrain.reshape(unlabeledXTrain.shape[0], 784)\n",
    "        model1.fit(labeledXTrain, labeledYTrain, batch_size = batchSize, epochs = 5,  \n",
    "                     validation_split = 0.1, verbose = 0)\n",
    "        unlabeledYHat1 = model1.predict_classes(unlabeledXTrain, batch_size = batchSize)\n",
    "        predProbs1 = model1.predict(unlabeledXTrain, batch_size = batchSize)\n",
    "        \n",
    "        labeledXTrain = labeledXTrain.reshape(labeledXTrain.shape[0], 28, 28, 1)\n",
    "        unlabeledXTrain = unlabeledXTrain.reshape(unlabeledXTrain.shape[0], 28, 28, 1)\n",
    "        model2.fit(labeledXTrain, labeledYTrain, batch_size = batchSize, epochs = 5,  \n",
    "                     validation_split = 0.1, verbose = 0)\n",
    "        unlabeledYHat2 = model2.predict_classes(unlabeledXTrain, batch_size = batchSize)\n",
    "        predProbs2 = model2.predict(unlabeledXTrain, batch_size = batchSize)\n",
    "        \n",
    "        # 3. Choose datapoints with high label probabilities and add them to labaled set\n",
    "        rows1, cols1 = np.where(predProbs1 > pThresh)\n",
    "        rows2, cols2 = np.where(predProbs2 > pThresh)\n",
    "        \n",
    "        highProbIdx = rows1\n",
    "        unlabeledYHat = cols1\n",
    "        for i in range(len(rows2)):\n",
    "            if rows2[i] not in highProbIdx:\n",
    "                highProbIdx = np.append(highProbIdx, rows2[i])\n",
    "                unlabeledYHat = np.append(unlabeledYHat, cols2[i])\n",
    "        \n",
    "        labeledXTrain = labeledXTrain.reshape(labeledXTrain.shape[0], 784)\n",
    "        unlabeledXTrain = unlabeledXTrain.reshape(unlabeledXTrain.shape[0], 784)\n",
    "        labeledXTrain = np.vstack((labeledXTrain, unlabeledXTrain[highProbIdx, :]))\n",
    "\n",
    "        # Check how much of the unlabeled data that was added to labeled data was wrongly classified\n",
    "        cMat = confusion_matrix(np.argmax(unlabeledYTrain[highProbIdx, :], axis = -1), unlabeledYHat)\n",
    "        if (shouldRandomizeFirstPrediction):\n",
    "            np.random.shuffle(unlabeledYHat[0:int(len(highProbIdx)/errorDenom)])\n",
    "            #shouldRandomizeFirstPrediction = False\n",
    "        labeledYTrain = np.vstack((labeledYTrain, to_categorical(unlabeledYHat, 10)))\n",
    "        print('Prob Idx Size ', highProbIdx.shape)\n",
    "        errorPct = 0\n",
    "        if unlabeledYTrain[highProbIdx, :].shape[0] > 0:\n",
    "            errorPct = 1 - sum(np.diag(cMat))/sum(sum(cMat))\n",
    "        wrongLabePct = np.append(wrongLabePct, errorPct)\n",
    "        \n",
    "        # Remove unlabeled data that was added to labeled data from labeled data\n",
    "        unlabeledXTrain = unlabeledXTrain[[i for i in range(unlabeledXTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledYTrain = unlabeledYTrain[[i for i in range(unlabeledYTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledData = np.copy(unlabeledYTrain)\n",
    "        count += 1\n",
    "    return([model1, model2, wrongLabePct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisedSeqImage(xTrain, yTrain, batchSize, layerSize, dropout, regLambda, labeledSize,\n",
    "                       selectionType, model):\n",
    "    data = splitData(xTrain, yTrain, labeledSize, selectionType)\n",
    "    xTrain = data[0]\n",
    "    yTrain = data[1]\n",
    "    \n",
    "    seqDenseModel = seqDenseNN(xTrain, layerSize, dropout, regLambda)\n",
    "    if model == 'CNN':\n",
    "        seqDenseModel = seqCNN(xTrain, layerSize, dropout)\n",
    "    yTrain = to_categorical(yTrain, 10)\n",
    "    seqDenseModel.fit(xTrain, yTrain, batch_size = batchSize, epochs = 5, \n",
    "                      validation_split = 0.1, verbose = 0)\n",
    "    return(seqDenseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfTrainTextModel(xTrain, yTrain, batchSize, maxIter, pThresh, labeledSize, selectionType,\n",
    "                       dropout, regLambda):\n",
    "    # Assumes that the classification model can also calculate class probabilities\n",
    "    \n",
    "    # 1. Randomly classify data as labeled and unlabeled according to label size\n",
    "    data = splitData(xTrain, yTrain, labeledSize, selectionType)\n",
    "    labeledXTrain = data[0]\n",
    "    labeledYTrain = data[1]    \n",
    "    unlabeledXTrain = data[2]\n",
    "    unlabeledYTrain = data[3]\n",
    "    \n",
    "    unlabeledData = np.copy(unlabeledYTrain)\n",
    "    max_features = 20000\n",
    "        \n",
    "    count = 0\n",
    "    wrongLabePct = []\n",
    "    \n",
    "    # Check if there are any more unlabeled datapoints left or if the number of iterations are done\n",
    "    while((count <= maxIter) and (len(unlabeledData) != 0)):\n",
    "        print(count)\n",
    "        print(len(unlabeledData))\n",
    "        # 2. Run a CNN on labeled data and get predicted labels and probabilities\n",
    "        seqDenseModel = seqDenseLSTM(max_features, dropout, regLambda)\n",
    "        seqDenseModel.fit(labeledXTrain, labeledYTrain, batch_size = batchSize, epochs = 5,\n",
    "                          validation_split = 0.1, verbose = 0)\n",
    "        unlabeledYHat = seqDenseModel.predict_classes(unlabeledXTrain, batch_size = batchSize)\n",
    "        predProbs = seqDenseModel.predict(unlabeledXTrain, batch_size = batchSize)\n",
    "        \n",
    "        # 3. Choose datapoints with high label probabilities and add them to labaled set\n",
    "        highProbIdx = np.where((predProbs > pThresh) | (predProbs < 1- pThresh))[0]\n",
    "        labeledXTrain = np.vstack((labeledXTrain, unlabeledXTrain[highProbIdx, :]))\n",
    "        labeledYTrain = np.hstack((labeledYTrain, \n",
    "                                   np.squeeze(np.asarray(unlabeledYHat[highProbIdx]))))\n",
    "        # Check how much of the unlabeled data that was added to labeled data was wrongly classified\n",
    "        unlabeledYHat = np.squeeze(np.asarray(unlabeledYHat[highProbIdx]))\n",
    "        cMat = confusion_matrix(unlabeledYTrain[highProbIdx], unlabeledYHat)\n",
    "        errorPct = 0\n",
    "        if unlabeledYTrain[highProbIdx].shape[0] > 0:\n",
    "            errorPct = 1 - sum(np.diag(cMat))/sum(sum(cMat))\n",
    "        wrongLabePct = np.append(wrongLabePct, errorPct)\n",
    "        \n",
    "        # Remove unlabeled data that was added to labeled data from labeled data\n",
    "        unlabeledXTrain = unlabeledXTrain[[i for i in range(unlabeledXTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledYTrain = unlabeledYTrain[[i for i in range(unlabeledYTrain.shape[0]) \\\n",
    "                                           if i not in highProbIdx], ]\n",
    "        unlabeledData = np.copy(unlabeledYTrain)\n",
    "        count += 1\n",
    "    return([seqDenseModel, wrongLabePct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisedSeqText(xTrain, yTrain, batchSize, dropout, regLambda, labeledSize,\n",
    "                       selectionType):    \n",
    "    data = splitData(xTrain, yTrain, labeledSize, selectionType)\n",
    "    xTrain = data[0]\n",
    "    yTrain = data[1]\n",
    "    \n",
    "    max_features = 20000\n",
    "    seqDenseModel = seqDenseLSTM(max_features, dropout, regLambda)\n",
    "    seqDenseModel.fit(xTrain, yTrain, batch_size = batchSize, epochs = 5, \n",
    "                      validation_split = 0.1, verbose = 0)\n",
    "    return(seqDenseModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
